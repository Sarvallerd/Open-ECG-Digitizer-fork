{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e686c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.segmentation import expand_labels\n",
    "from typing import Tuple\n",
    "import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1415056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECG_FOLDER = '../../data/ecg_ahus_phone'\n",
    "SAVE_FOLDER = '../../data/redacted_ecg_ahus_phone'\n",
    "DISPLAY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fae55d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Redacting images: 100%|██████████| 325/325 [06:34<00:00,  1.22s/image]\n"
     ]
    }
   ],
   "source": [
    "def redact_image(\n",
    "        image_path: str,\n",
    "        redacted_treshold_grayscale: int = 60,\n",
    "        min_redacted_area_proportion: float = 3e-5,\n",
    "        expand_redact_pixels: int = 10,\n",
    "        display: bool = False\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    img_gray = img.convert('L')\n",
    "    img_np = np.array(img_gray)\n",
    "\n",
    "    if display:\n",
    "        plt.imshow(img_np)\n",
    "\n",
    "    img_blurred = gaussian_filter(img_np, sigma=5)\n",
    "    redacted = img_blurred < redacted_treshold_grayscale\n",
    "\n",
    "    if display:\n",
    "        plt.figure()\n",
    "        plt.imshow(redacted, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    labeled = label(redacted)\n",
    "    regions = regionprops(labeled)\n",
    "\n",
    "    regions_filtered = []\n",
    "    ids = []\n",
    "\n",
    "    for region in regions:\n",
    "        if region.area / img_np.size > min_redacted_area_proportion:\n",
    "            regions_filtered.append(region)\n",
    "            ids.append(region.label)\n",
    "\n",
    "\n",
    "    areas = [region.area for region in regions_filtered]\n",
    "    perimeters = [region.perimeter for region in regions_filtered]\n",
    "\n",
    "    if display:\n",
    "        plt.plot(areas, perimeters, 'o')\n",
    "        plt.xlabel('Area')\n",
    "        plt.ylabel('Perimeter')\n",
    "        plt.title('Area vs Perimeter of Regions')\n",
    "        plt.grid()\n",
    "\n",
    "    regions_after_filtering = np.isin(labeled, ids)\n",
    "    regions_after_filtering = expand_labels(regions_after_filtering, distance=expand_redact_pixels)\n",
    "\n",
    "    if display:\n",
    "        plt.figure()\n",
    "        plt.imshow(regions_after_filtering, cmap='gray')\n",
    "\n",
    "    img_redacted = np.array(img)\n",
    "    img_redacted[regions_after_filtering > 0] = np.array([0, 255, 0])\n",
    "\n",
    "    return img_redacted, regions_after_filtering\n",
    "\n",
    "\n",
    "image_names = tqdm.tqdm(os.listdir(ECG_FOLDER), desc='Redacting images', unit='image')\n",
    "\n",
    "for image_name in image_names:\n",
    "    path = os.path.join(ECG_FOLDER, image_name)\n",
    "\n",
    "    redacted_image, regions_after_filtering = redact_image(path, display=DISPLAY)\n",
    "    Image.fromarray(redacted_image).save(os.path.join(SAVE_FOLDER, image_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
